# AI Dataset Radar Configuration

# Database configuration
database:
  path: data/radar.db

# Data sources configuration
sources:
  huggingface:
    enabled: true
    limit: 50  # Number of datasets to fetch

  paperswithcode:
    enabled: false  # API migrated to Hugging Face (2026)
    limit: 50  # Number of benchmarks to fetch

  arxiv:
    enabled: true
    limit: 50  # Number of papers to fetch
    categories:
      - cs.CL  # Computation and Language
      - cs.CV  # Computer Vision
      - cs.LG  # Machine Learning

  # Early signal sources (Phase 1.5)
  github:
    enabled: true
    limit: 30  # Number of repos to fetch
    days: 7  # Look back period
    token: ${GITHUB_TOKEN}  # Optional: for higher rate limits

  hf_papers:
    enabled: true
    limit: 50  # Number of papers to fetch
    days: 7  # Look back period

  # Semantic Scholar for citation tracking (v3)
  # Get API key at: https://www.semanticscholar.org/product/api (recommended)
  # Without API key: 100 requests / 5 min; With API key: 1 request / sec
  semantic_scholar:
    enabled: true
    limit: 100  # Number of papers to fetch
    months_back: 6  # Look back period
    min_citations: 20  # Minimum citations filter
    min_monthly_growth: 10  # Minimum monthly citation growth
    api_key: ${SEMANTIC_SCHOLAR_API_KEY}  # Strongly recommended for production use

# Model tracking configuration
models:
  enabled: true
  limit: 100  # Number of models to fetch
  min_downloads: 1000  # Only track models with sufficient popularity

# Analysis configuration
analysis:
  trend_days: [7, 30]  # Calculate trends for these periods
  min_growth_alert: 0.5  # Alert when growth exceeds 50%

# Value analysis configuration (v3)
value_analysis:
  min_score: 0  # Minimum score to include in analysis

  # Model card analysis
  model_cards:
    enabled: true
    min_downloads: 1000  # Minimum model downloads to analyze
    limit: 500  # Max models to analyze
    min_usage: 3  # Dataset must be used by 3+ models

  # SOTA tracking (requires Papers with Code API)
  sota:
    enabled: false  # API migrated to Hugging Face (2026)
    top_n: 10  # Top N SOTA results per task
    areas:  # Priority areas
      - robotics
      - code-generation
      - question-answering
      - text-generation
      - image-classification

  # Value scoring weights
  scoring:
    sota_usage: 30
    citation_growth: 20
    model_usage: 20
    top_institution: 15
    paper_and_code: 10
    large_scale: 5

# LLM configuration (for future use)
llm:
  enabled: false  # Enable in Phase 2
  provider: anthropic
  model: claude-3-haiku-20240307

# Filtering options
filters:
  min_downloads: 0  # Minimum download count (for Hugging Face)
  keywords: []  # Filter by keywords (empty = no filter)
  days: 7  # Only include items from the last N days

# Domain focus areas for business intelligence filtering
focus_areas:
  robotics:
    enabled: true
    keywords:
      - robotics
      - manipulation
      - embodied
      - rlbench
      - lerobot
      - dexterous
      - humanoid
      - gripper
      - robot arm
      - pick and place
      - grasping
      - locomotion
    hf_tags:
      - task_categories:robotics

  rlhf:
    enabled: true
    keywords:
      - preference
      - human feedback
      - RLHF
      - DPO
      - reward model
      - alignment
      - instruction tuning
      - reinforcement learning from human feedback
    hf_tags:
      - task_categories:reinforcement-learning

  multimodal:
    enabled: true
    keywords:
      - vision-language
      - VLM
      - multimodal
      - image-text
      - visual question answering
      - image captioning
      - video understanding
      - CLIP
      - LLaVA
    hf_tags:
      - task_categories:visual-question-answering
      - task_categories:image-to-text

  code:
    enabled: false
    keywords:
      - code generation
      - programming
      - code completion
      - software engineering
      - code review
    hf_tags:
      - task_categories:text-generation

  # Post-training focus areas
  sft:
    enabled: true
    keywords:
      - instruction tuning
      - supervised fine-tuning
      - instruction following
      - chat dataset
      - conversational
      - ShareGPT
      - Alpaca
      - assistant
      - dialogue
      - FLAN
      - Dolly
      - OpenOrca
      - WizardLM
      - Evol-Instruct
      - instruct dataset
    hf_tags:
      - task_categories:conversational
      - task_categories:text-generation

  preference:
    enabled: true
    keywords:
      - preference
      - chosen rejected
      - DPO
      - RLHF
      - reward model
      - human feedback
      - pairwise comparison
      - UltraFeedback
      - HelpSteer
      - Nectar
      - hh-rlhf
      - helpful harmless
      - preference ranking
      - ORPO
      - KTO
      - IPO
    hf_tags:
      - task_categories:text-classification

  agent:
    enabled: true
    keywords:
      - agent
      - tool use
      - function calling
      - API call
      - web navigation
      - trajectory
      - action sequence
      - SWE-bench
      - WebArena
      - ToolBench
      - AgentBench
      - Mind2Web
      - GAIA
      - AgentInstruct
      - tool-augmented
      - ReAct
      - task automation
    hf_tags:
      - task_categories:reinforcement-learning

  evaluation:
    enabled: true
    keywords:
      - benchmark
      - evaluation dataset
      - MMLU
      - HumanEval
      - GPQA
      - ARC-Challenge
      - BigBench
      - MATH dataset
      - GSM8K
      - TruthfulQA
      - HellaSwag
      - WinoGrande
      - test set
      - exam dataset
      - Humanity's Last Exam
      - HLE
      - hard evaluation
    hf_tags:
      - task_categories:question-answering

# Organization tracking for competitive intelligence
tracked_orgs:
  # Major tech companies
  bytedance:
    - 字节
    - ByteDance
    - doubao
    - 豆包
    - TikTok
  alibaba:
    - 阿里
    - Alibaba
    - Qwen
    - 通义
    - DAMO
  tencent:
    - 腾讯
    - Tencent
    - Hunyuan
    - 优图
  baidu:
    - 百度
    - Baidu
    - ERNIE
    - 文心
  huawei:
    - 华为
    - Huawei
    - 盘古
  openai:
    - OpenAI
  google:
    - Google
    - DeepMind
  meta:
    - Meta
    - FAIR

  # Post-training specialists
  anthropic:
    - Anthropic
    - Claude
  mistral:
    - Mistral
    - MistralAI
  deepseek:
    - DeepSeek
    - 深度求索
  yi:
    - 01.AI
    - Yi
    - 零一万物
  zhipu:
    - 智谱
    - Zhipu
    - GLM
    - ChatGLM
  moonshot:
    - Moonshot
    - 月之暗面
    - Kimi

  # Research labs (post-training focus)
  lmsys:
    - LMSys
    - LMSYS
    - Chatbot Arena
    - Vicuna
  eleutherai:
    - EleutherAI
    - Pythia
  allen_ai:
    - Allen AI
    - AI2
    - Tulu
    - OLMo
  berkeley:
    - UC Berkeley
    - Berkeley
    - BAIR
    - Gorilla
    - Koala
    - Starling
  stanford:
    - Stanford
    - Alpaca
    - HELM
  nvidia:
    - NVIDIA
    - HelpSteer
    - Nemotron
  huggingface:
    - Hugging Face
    - HuggingFace
    - BigCode
    - StarCoder
    - Zephyr
    - OpenAssistant

# Opportunity detection settings
opportunities:
  # Signals indicating annotation needs in papers
  annotation_signals:
    # General signals
    - human annotation
    - manually labeled
    - crowdsourced
    - we collected
    - data collection
    - benchmark
    - human evaluation
    - training data
    - annotation guideline

    # SFT signals
    - instruction dataset
    - instruction tuning data
    - fine-tuning dataset
    - chat data
    - dialogue dataset
    - conversational data

    # RLHF/Preference signals
    - human preference
    - preference data
    - RLHF
    - reward model training
    - pairwise comparison
    - chosen and rejected
    - preference annotation
    - human feedback
    - alignment data

    # Agent signals
    - trajectory data
    - action annotation
    - tool use data
    - function calling dataset
    - web interaction data
    - agent training data

    # Evaluation signals
    - evaluation dataset
    - test set
    - benchmark dataset
    - ground truth
    - gold labels
    - expert annotation

  # Data factory detection
  data_factory:
    min_datasets: 3  # Minimum datasets published
    days: 7  # Within this many days

# Notification settings
notifications:
  console:
    enabled: true
    color: true  # Use colored output

  markdown:
    enabled: false  # Legacy format, disabled by default
    output_dir: data

  business_intel:
    enabled: true  # New business intelligence report format
    output_dir: data

  email:
    enabled: false
    smtp_server: ${SMTP_SERVER}
    smtp_port: 587
    username: ${SMTP_USERNAME}
    password: ${SMTP_PASSWORD}
    from_addr: ${EMAIL_FROM}
    to_addrs:
      - ${EMAIL_TO}

  webhook:
    enabled: false
    url: ${WEBHOOK_URL}

# Output settings
output:
  json_dir: data  # Directory to save JSON data
