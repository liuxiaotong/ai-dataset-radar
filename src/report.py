"""High-Value Dataset Report Generator for AI Dataset Radar v3.

Generates comprehensive reports focusing on dataset value scores,
SOTA associations, citation trends, and domain-specific insights.
"""

import os
from datetime import datetime
from typing import Optional


class ValueReportGenerator:
    """Generate high-value dataset reports."""

    def __init__(self, output_dir: str = "data"):
        """Initialize the report generator.

        Args:
            output_dir: Directory to save reports.
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

    def generate_report(
        self,
        scored_datasets: list[dict],
        sota_results: Optional[dict] = None,
        citation_data: Optional[list[dict]] = None,
        model_card_results: Optional[dict] = None,
        domain_breakdown: Optional[dict] = None,
    ) -> str:
        """Generate a comprehensive value report.

        Args:
            scored_datasets: List of datasets with value scores.
            sota_results: Results from SOTA analysis.
            citation_data: Citation tracking data.
            model_card_results: Results from model card analysis.
            domain_breakdown: Datasets grouped by domain.

        Returns:
            Path to the generated report file.
        """
        lines = []

        # Header
        lines.extend([
            "# é«˜ä»·å€¼æ•°æ®é›†å‘¨æŠ¥",
            f"*Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*",
            "",
        ])

        # Top 10 high-value datasets
        lines.extend(self._generate_top_datasets_section(scored_datasets))

        # Newly discovered high-value datasets
        lines.extend(self._generate_new_discoveries_section(scored_datasets))

        # Domain breakdown
        if domain_breakdown:
            lines.extend(self._generate_domain_section(domain_breakdown))

        # SOTA associations
        if sota_results:
            lines.extend(self._generate_sota_section(sota_results))

        # Citation trends
        if citation_data:
            lines.extend(self._generate_citation_section(citation_data))

        # Model usage insights
        if model_card_results:
            lines.extend(self._generate_model_usage_section(model_card_results))

        # Papers worth attention
        lines.extend(self._generate_papers_section(scored_datasets))

        # Summary statistics
        lines.extend(self._generate_summary_section(
            scored_datasets, sota_results, citation_data, model_card_results
        ))

        # Footer
        lines.extend([
            "",
            "---",
            "> Report generated by AI Dataset Radar v3 â€” High-Value Dataset Discovery System",
        ])

        report_content = "\n".join(lines)

        # Save report
        date_str = datetime.now().strftime("%Y-%m-%d")
        filename = f"value_report_{date_str}.md"
        filepath = os.path.join(self.output_dir, filename)

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(report_content)

        return filepath

    def _generate_top_datasets_section(self, scored_datasets: list[dict]) -> list[str]:
        """Generate the top datasets section."""
        lines = [
            "## ðŸ† Top 10 é«˜ä»·å€¼æ•°æ®é›†",
            "",
            "| æŽ’å | æ•°æ®é›† | è¯„åˆ† | SOTAæ¨¡åž‹æ•° | å¼•ç”¨å¢žé•¿ | é¢†åŸŸ | æœºæž„ |",
            "|------|--------|------|------------|----------|------|------|",
        ]

        for i, ds in enumerate(scored_datasets[:10], 1):
            name = ds.get("dataset_name", "Unknown")[:30]
            score = ds.get("total_score", 0)
            sota_count = ds.get("signals", {}).get("sota_model_count", 0)
            cite_growth = ds.get("signals", {}).get("citation_monthly_growth", 0)
            domain = ds.get("original_data", {}).get("domain", "-")
            institution = ds.get("signals", {}).get("institution", "-") or "-"

            if len(institution) > 15:
                institution = institution[:12] + "..."

            cite_str = f"{cite_growth:.1f}/æœˆ" if cite_growth else "-"

            lines.append(
                f"| {i} | {name} | {score} | {sota_count} | {cite_str} | {domain or '-'} | {institution} |"
            )

        lines.append("")
        return lines

    def _generate_new_discoveries_section(self, scored_datasets: list[dict]) -> list[str]:
        """Generate section for newly discovered datasets."""
        lines = [
            "## ðŸ“ˆ æ–°æ™‹é«˜ä»·å€¼æ•°æ®é›†",
            "",
        ]

        # Filter for datasets that might be new (high score but low awareness)
        new_datasets = [
            ds for ds in scored_datasets
            if ds.get("total_score", 0) >= 40
            and ds.get("signals", {}).get("model_usage_count", 0) < 5
        ][:5]

        if new_datasets:
            lines.append("| æ•°æ®é›† | è¯„åˆ† | å‘çŽ°åŽŸå›  | æ½œåœ¨ä»·å€¼ |")
            lines.append("|--------|------|----------|----------|")

            for ds in new_datasets:
                name = ds.get("dataset_name", "Unknown")[:25]
                score = ds.get("total_score", 0)

                # Determine discovery reason
                reasons = []
                signals = ds.get("signals", {})
                if signals.get("sota_model_count", 0) > 0:
                    reasons.append("SOTAä½¿ç”¨")
                if signals.get("citation_monthly_growth", 0) >= 10:
                    reasons.append("å¼•ç”¨å¿«å¢ž")
                if ds.get("is_top_institution"):
                    reasons.append("é¡¶çº§æœºæž„")

                reason_str = ", ".join(reasons) if reasons else "ç»¼åˆè¯„åˆ†"

                # Potential value assessment
                if score >= 60:
                    potential = "æžé«˜"
                elif score >= 40:
                    potential = "é«˜"
                else:
                    potential = "ä¸­ç­‰"

                lines.append(f"| {name} | {score} | {reason_str} | {potential} |")
        else:
            lines.append("*æœ¬å‘¨æš‚æ— æ–°å‘çŽ°çš„é«˜ä»·å€¼æ•°æ®é›†*")

        lines.append("")
        return lines

    def _generate_domain_section(self, domain_breakdown: dict) -> list[str]:
        """Generate domain-specific sections."""
        lines = [
            "## ðŸ¤– æŒ‰é¢†åŸŸåˆ†ç±»",
            "",
        ]

        domain_labels = {
            "robotics": "Robotics æœºå™¨äºº",
            "nlp": "LLM/NLP è¯­è¨€æ¨¡åž‹",
            "vision": "Vision/Multimodal è§†è§‰å¤šæ¨¡æ€",
            "code": "Code Generation ä»£ç ç”Ÿæˆ",
            "rlhf": "RLHF/Alignment å¯¹é½",
        }

        for domain, datasets in domain_breakdown.items():
            if not datasets:
                continue

            label = domain_labels.get(domain, domain.title())
            lines.append(f"### {label}")
            lines.append("")

            # Top 5 in each domain
            top_domain = sorted(
                datasets,
                key=lambda x: x.get("total_score", x.get("value_score", 0)),
                reverse=True,
            )[:5]

            if top_domain:
                lines.append("| æ•°æ®é›† | è¯„åˆ† | ç‰¹ç‚¹ |")
                lines.append("|--------|------|------|")

                for ds in top_domain:
                    name = ds.get("dataset_name", ds.get("name", "Unknown"))[:30]
                    score = ds.get("total_score", ds.get("value_score", 0))

                    features = []
                    if ds.get("signals", {}).get("sota_model_count", 0) > 0:
                        features.append("SOTA")
                    if ds.get("is_top_institution") or ds.get("signals", {}).get("institution"):
                        features.append("é¡¶çº§æœºæž„")
                    if ds.get("signals", {}).get("has_paper"):
                        features.append("æœ‰è®ºæ–‡")

                    feature_str = ", ".join(features) if features else "-"
                    lines.append(f"| {name} | {score} | {feature_str} |")

            lines.append("")

        return lines

    def _generate_sota_section(self, sota_results: dict) -> list[str]:
        """Generate SOTA association section."""
        lines = [
            "## ðŸŽ¯ SOTA å…³è”åˆ†æž",
            "",
        ]

        ranked = sota_results.get("ranked_datasets", [])[:10]

        if ranked:
            lines.append("| æ•°æ®é›† | SOTAæ¨¡åž‹æ•° | è¦†ç›–é¢†åŸŸ | ä»£è¡¨æ¨¡åž‹ |")
            lines.append("|--------|------------|----------|----------|")

            for ds in ranked:
                name = ds.get("name", "Unknown")[:25]
                count = ds.get("sota_model_count", 0)
                areas = ", ".join(ds.get("areas", [])[:2]) or "-"

                top_model = "-"
                if ds.get("sota_models"):
                    top_model = ds["sota_models"][0].get("model_name", "-")[:20]

                lines.append(f"| {name} | {count} | {areas} | {top_model} |")
        else:
            lines.append("*æš‚æ—  SOTA å…³è”æ•°æ®*")

        lines.append("")
        return lines

    def _generate_citation_section(self, citation_data: list[dict]) -> list[str]:
        """Generate citation trends section."""
        lines = [
            "## ðŸ“š å¼•ç”¨è¶‹åŠ¿",
            "",
        ]

        # Filter for high-growth papers
        high_growth = [
            p for p in citation_data
            if p.get("citation_monthly_growth", 0) >= 10
        ][:10]

        if high_growth:
            lines.append("| è®ºæ–‡/æ•°æ®é›† | å½“å‰å¼•ç”¨ | æœˆå¢žé•¿ | å¢žé•¿çŽ‡ |")
            lines.append("|-------------|----------|--------|--------|")

            for paper in high_growth:
                title = paper.get("paper_title", paper.get("dataset_name", "Unknown"))[:30]
                citations = paper.get("citation_count", 0)
                growth = paper.get("citation_monthly_growth", 0)

                rate = f"{(growth / max(citations - growth, 1) * 100):.1f}%" if citations > growth else "N/A"

                lines.append(f"| {title} | {citations} | +{growth:.1f} | {rate} |")
        else:
            lines.append("*æš‚æ— æ˜¾è‘—å¼•ç”¨å¢žé•¿æ•°æ®*")

        lines.append("")
        return lines

    def _generate_model_usage_section(self, model_card_results: dict) -> list[str]:
        """Generate model usage insights section."""
        lines = [
            "## ðŸ”— æ¨¡åž‹ä½¿ç”¨åˆ†æž",
            "",
        ]

        valuable = model_card_results.get("valuable_datasets", [])[:10]

        if valuable:
            lines.append("| æ•°æ®é›† | ä½¿ç”¨æ¨¡åž‹æ•° | ç´¯è®¡ä¸‹è½½é‡ | ä»£è¡¨æ¨¡åž‹ |")
            lines.append("|--------|------------|------------|----------|")

            for ds in valuable:
                name = ds.get("name", "Unknown")[:25]
                usage = ds.get("usage_count", 0)
                downloads = ds.get("total_model_downloads", 0)
                top_model = ds.get("top_model", "-")[:20] if ds.get("top_model") else "-"

                downloads_str = f"{downloads:,}" if downloads else "-"

                lines.append(f"| {name} | {usage} | {downloads_str} | {top_model} |")
        else:
            lines.append("*æš‚æ— æ¨¡åž‹ä½¿ç”¨æ•°æ®*")

        lines.append("")
        return lines

    def _generate_papers_section(self, scored_datasets: list[dict]) -> list[str]:
        """Generate section for papers worth attention."""
        lines = [
            "## ðŸ”¬ å€¼å¾—å…³æ³¨çš„æ–°è®ºæ–‡",
            "",
        ]

        # Extract papers from scored datasets
        papers_with_data = [
            ds for ds in scored_datasets
            if ds.get("signals", {}).get("has_paper")
            and ds.get("total_score", 0) >= 30
        ][:10]

        if papers_with_data:
            lines.append("| æ•°æ®é›†/è®ºæ–‡ | è¯„åˆ† | æœºæž„ | é“¾æŽ¥ |")
            lines.append("|-------------|------|------|------|")

            for ds in papers_with_data:
                name = ds.get("dataset_name", "Unknown")[:30]
                score = ds.get("total_score", 0)
                inst = ds.get("signals", {}).get("institution", "-") or "-"
                if len(inst) > 12:
                    inst = inst[:10] + ".."

                paper_url = ds.get("original_data", {}).get("paper_url")
                arxiv_id = ds.get("original_data", {}).get("arxiv_id")

                if paper_url:
                    link = f"[Link]({paper_url})"
                elif arxiv_id:
                    link = f"[arXiv](https://arxiv.org/abs/{arxiv_id})"
                else:
                    link = "-"

                lines.append(f"| {name} | {score} | {inst} | {link} |")
        else:
            lines.append("*æš‚æ— æ–°è®ºæ–‡æŽ¨è*")

        lines.append("")
        return lines

    def _generate_summary_section(
        self,
        scored_datasets: list[dict],
        sota_results: Optional[dict],
        citation_data: Optional[list[dict]],
        model_card_results: Optional[dict],
    ) -> list[str]:
        """Generate summary statistics section."""
        lines = [
            "## ðŸ“Š ç»Ÿè®¡æ‘˜è¦",
            "",
        ]

        total = len(scored_datasets)
        high_value = len([d for d in scored_datasets if d.get("total_score", 0) >= 60])
        medium_value = len([d for d in scored_datasets if 40 <= d.get("total_score", 0) < 60])
        top_inst = len([d for d in scored_datasets if d.get("is_top_institution")])

        lines.append(f"- **åˆ†æžæ•°æ®é›†æ€»æ•°:** {total} ä¸ª")
        lines.append(f"- **é«˜ä»·å€¼æ•°æ®é›† (â‰¥60åˆ†):** {high_value} ä¸ª")
        lines.append(f"- **ä¸­ç­‰ä»·å€¼æ•°æ®é›† (40-59åˆ†):** {medium_value} ä¸ª")
        lines.append(f"- **é¡¶çº§æœºæž„æ•°æ®é›†:** {top_inst} ä¸ª")

        if sota_results:
            sota_count = sota_results.get("unique_datasets", 0)
            lines.append(f"- **SOTA å…³è”æ•°æ®é›†:** {sota_count} ä¸ª")

        if citation_data:
            high_cite = len([p for p in citation_data if p.get("citation_monthly_growth", 0) >= 10])
            lines.append(f"- **é«˜å¼•ç”¨å¢žé•¿è®ºæ–‡:** {high_cite} ç¯‡")

        if model_card_results:
            model_count = model_card_results.get("models_analyzed", 0)
            lines.append(f"- **åˆ†æžæ¨¡åž‹æ•°é‡:** {model_count} ä¸ª")

        lines.append("")
        return lines


def generate_value_report(
    scored_datasets: list[dict],
    output_dir: str = "data",
    **kwargs,
) -> str:
    """Convenience function to generate a value report.

    Args:
        scored_datasets: List of datasets with value scores.
        output_dir: Directory to save the report.
        **kwargs: Additional data (sota_results, citation_data, etc.)

    Returns:
        Path to the generated report.
    """
    generator = ValueReportGenerator(output_dir)
    return generator.generate_report(scored_datasets, **kwargs)
