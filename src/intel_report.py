"""Intelligence report generator for competitive analysis.

Generates structured markdown reports focused on:
- US AI Labs activity
- Data vendor (competitor) monitoring
- Datasets categorized by training type
"""

from datetime import datetime
from typing import Optional


class IntelReportGenerator:
    """Generate competitive intelligence reports."""

    def __init__(self, config: dict):
        """Initialize the report generator.

        Args:
            config: Configuration dict.
        """
        self.config = config
        report_config = config.get("report", {})
        self.limits = report_config.get("limits", {})

    def generate(
        self,
        lab_activity: dict,
        vendor_activity: dict,
        datasets_by_type: dict,
        papers: list[dict],
    ) -> str:
        """Generate the full intelligence report.

        Args:
            lab_activity: Activity from AI labs.
            vendor_activity: Activity from data vendors.
            datasets_by_type: Datasets grouped by training type.
            papers: Relevant research papers.

        Returns:
            Markdown formatted report.
        """
        lines = []

        # Header
        lines.append("# AI æ•°æ®æƒ…æŠ¥å‘¨æŠ¥")
        lines.append(f"*Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}*")
        lines.append("")

        # Executive Summary
        lines.extend(self._generate_summary(lab_activity, vendor_activity, datasets_by_type))

        # US AI Labs Activity
        lines.extend(self._generate_labs_section(lab_activity))

        # Data Vendor Activity
        lines.extend(self._generate_vendors_section(vendor_activity))

        # Datasets by Type
        lines.extend(self._generate_datasets_section(datasets_by_type))

        # Papers
        lines.extend(self._generate_papers_section(papers))

        # Footer
        lines.append("---")
        lines.append("*Report generated by AI Dataset Radar v4 - Competitive Intelligence System*")

        return "\n".join(lines)

    def _generate_summary(
        self,
        lab_activity: dict,
        vendor_activity: dict,
        datasets_by_type: dict,
    ) -> list[str]:
        """Generate executive summary section."""
        lines = []
        lines.append("## ğŸ“Š æœ¬å‘¨æ‘˜è¦")
        lines.append("")

        # Count labs with activity
        active_labs = 0
        lab_datasets = 0
        for category in lab_activity.get("labs", {}).values():
            for org_data in category.values():
                if org_data.get("datasets") or org_data.get("models"):
                    active_labs += 1
                    lab_datasets += len(org_data.get("datasets", []))

        # Count vendors
        active_vendors = 0
        vendor_datasets = 0
        for tier in vendor_activity.get("vendors", {}).values():
            for vendor_data in tier.values():
                if vendor_data.get("datasets"):
                    active_vendors += 1
                    vendor_datasets += len(vendor_data.get("datasets", []))

        # Count by type
        type_counts = {dtype: len(ds) for dtype, ds in datasets_by_type.items()}
        total_relevant = sum(type_counts.values())

        lines.append(f"- **æ´»è·ƒ AI Labs**: {active_labs} å®¶ï¼Œå‘å¸ƒ {lab_datasets} ä¸ªæ•°æ®é›†")
        lines.append(f"- **æ´»è·ƒæ•°æ®ä¾›åº”å•†**: {active_vendors} å®¶ï¼Œå‘å¸ƒ {vendor_datasets} ä¸ªæ•°æ®é›†")
        lines.append(f"- **é«˜ä»·å€¼æ•°æ®é›†**: {total_relevant} ä¸ªï¼ˆæŒ‰ç±»å‹åˆ†ç±»ï¼‰")

        if type_counts:
            top_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)[:3]
            top_str = ", ".join(f"{dtype}({count})" for dtype, count in top_types)
            lines.append(f"- **çƒ­é—¨ç±»å‹**: {top_str}")

        lines.append("")
        return lines

    def _generate_labs_section(self, lab_activity: dict) -> list[str]:
        """Generate US AI Labs section."""
        lines = []
        lines.append("## ğŸ”¬ ç¾å›½ AI Labs åŠ¨æ€")
        lines.append("")

        labs = lab_activity.get("labs", {})
        limit = self.limits.get("labs_per_category", 10)

        # Frontier Labs
        frontier = labs.get("frontier_labs", {})
        if frontier:
            lines.append("### Frontier Labsï¼ˆä¸€çº¿å®éªŒå®¤ï¼‰")
            lines.append("")
            lines.append("| æœºæ„ | æœ¬å‘¨æ•°æ®é›† | æœ¬å‘¨æ¨¡å‹ | ä»£è¡¨å†…å®¹ |")
            lines.append("|------|-----------|---------|---------|")

            for org_name, org_data in list(frontier.items())[:limit]:
                ds_count = len(org_data.get("datasets", []))
                model_count = len(org_data.get("models", []))

                # Get representative dataset
                rep = ""
                if org_data.get("datasets"):
                    ds = org_data["datasets"][0]
                    rep = ds.get("id", "").split("/")[-1][:30]
                elif org_data.get("models"):
                    model = org_data["models"][0]
                    rep = model.get("id", "").split("/")[-1][:30]

                org_display = org_name.replace("_", " ").title()
                lines.append(f"| {org_display} | {ds_count} | {model_count} | {rep} |")

            lines.append("")

            # Detail for frontier labs with datasets
            for org_name, org_data in list(frontier.items())[:5]:
                if org_data.get("datasets"):
                    org_display = org_name.replace("_", " ").title()
                    lines.append(f"**{org_display}** æ•°æ®é›†:")
                    for ds in org_data["datasets"][:3]:
                        ds_id = ds.get("id", "Unknown")
                        ds_name = ds_id.split("/")[-1] if "/" in ds_id else ds_id
                        downloads = ds.get("downloads", 0)
                        lines.append(f"- [{ds_name}](https://huggingface.co/datasets/{ds_id}) ({downloads:,} downloads)")
                    lines.append("")

        # Emerging Labs
        emerging = labs.get("emerging_labs", {})
        if emerging:
            lines.append("### Emerging Labsï¼ˆæ–°å…´å®éªŒå®¤ï¼‰")
            lines.append("")
            lines.append("| æœºæ„ | æ•°æ®é›† | æ¨¡å‹ | ä»£è¡¨å†…å®¹ |")
            lines.append("|------|--------|------|---------|")

            for org_name, org_data in list(emerging.items())[:limit]:
                ds_count = len(org_data.get("datasets", []))
                model_count = len(org_data.get("models", []))
                rep = ""
                if org_data.get("datasets"):
                    rep = org_data["datasets"][0].get("id", "").split("/")[-1][:30]

                org_display = org_name.replace("_", " ").title()
                lines.append(f"| {org_display} | {ds_count} | {model_count} | {rep} |")

            lines.append("")

        # Research Labs
        research = labs.get("research_labs", {})
        if research:
            lines.append("### Research Labsï¼ˆç ”ç©¶æœºæ„ï¼‰")
            lines.append("")
            lines.append("| æœºæ„ | æ•°æ®é›† | æ¨¡å‹ | ä»£è¡¨å†…å®¹ |")
            lines.append("|------|--------|------|---------|")

            for org_name, org_data in list(research.items())[:limit]:
                ds_count = len(org_data.get("datasets", []))
                model_count = len(org_data.get("models", []))
                rep = ""
                if org_data.get("datasets"):
                    rep = org_data["datasets"][0].get("id", "").split("/")[-1][:30]

                org_display = org_name.replace("_", " ").title()
                lines.append(f"| {org_display} | {ds_count} | {model_count} | {rep} |")

            lines.append("")

        if not frontier and not emerging and not research:
            lines.append("*æœ¬å‘¨æ— ç›‘æ§ç›®æ ‡çš„æ–°æ´»åŠ¨*")
            lines.append("")

        return lines

    def _generate_vendors_section(self, vendor_activity: dict) -> list[str]:
        """Generate data vendor section."""
        lines = []
        lines.append("## ğŸ¢ æ•°æ®ä¾›åº”å•†åŠ¨æ€ï¼ˆç«å“ç›‘æ§ï¼‰")
        lines.append("")

        vendors = vendor_activity.get("vendors", {})
        limit = self.limits.get("vendors", 5)

        # Premium vendors
        premium = vendors.get("premium", {})
        if premium:
            lines.append("### å¤´éƒ¨ä¾›åº”å•†")
            lines.append("")

            for vendor_name, vendor_data in list(premium.items())[:limit]:
                vendor_display = vendor_name.replace("_", " ").title()
                lines.append(f"**{vendor_display}**")

                if vendor_data.get("datasets"):
                    lines.append(f"- æœ¬å‘¨å‘å¸ƒ {len(vendor_data['datasets'])} ä¸ªæ•°æ®é›†")
                    for ds in vendor_data["datasets"][:3]:
                        ds_id = ds.get("id", "Unknown")
                        ds_name = ds_id.split("/")[-1] if "/" in ds_id else ds_id
                        lines.append(f"  - [{ds_name}](https://huggingface.co/datasets/{ds_id})")
                else:
                    lines.append("- æœ¬å‘¨æ— æ–°æ•°æ®é›†")

                if vendor_data.get("blog_url"):
                    lines.append(f"- åšå®¢: {vendor_data['blog_url']}")

                lines.append("")

        # Specialized vendors
        specialized = vendors.get("specialized", {})
        if specialized:
            lines.append("### ä¸“ä¸šä¾›åº”å•†")
            lines.append("")
            lines.append("| ä¾›åº”å•† | æœ¬å‘¨æ•°æ®é›† | ä»£è¡¨å†…å®¹ |")
            lines.append("|--------|-----------|---------|")

            for vendor_name, vendor_data in list(specialized.items())[:limit]:
                ds_count = len(vendor_data.get("datasets", []))
                rep = ""
                if vendor_data.get("datasets"):
                    rep = vendor_data["datasets"][0].get("id", "").split("/")[-1][:30]

                vendor_display = vendor_name.replace("_", " ").title()
                lines.append(f"| {vendor_display} | {ds_count} | {rep} |")

            lines.append("")

        if not premium and not specialized:
            lines.append("*æœ¬å‘¨æ— ç›‘æ§ä¾›åº”å•†çš„æ–°æ´»åŠ¨*")
            lines.append("")

        return lines

    def _generate_datasets_section(self, datasets_by_type: dict) -> list[str]:
        """Generate datasets by type section."""
        lines = []
        lines.append("## ğŸ“Š é«˜ä»·å€¼æ•°æ®é›†ï¼ˆæŒ‰ç±»å‹ï¼‰")
        lines.append("")

        type_display = {
            "preference": ("ğŸ¯", "RLHF/DPO åå¥½æ•°æ®"),
            "reward_model": ("ğŸ†", "Reward Model æ•°æ®"),
            "sft": ("ğŸ“š", "SFT æŒ‡ä»¤å¾®è°ƒæ•°æ®"),
            "code": ("ğŸ’»", "ä»£ç ç”Ÿæˆ/æ‰§è¡Œ"),
            "agent": ("ğŸ¤–", "Agent/å·¥å…·ä½¿ç”¨"),
            "embodied": ("ğŸ¦¾", "å…·èº«æ™ºèƒ½"),
            "safety": ("ğŸ›¡ï¸", "å®‰å…¨/å¯¹é½"),
        }

        limit = self.limits.get("datasets_per_type", 10)

        for dtype, datasets in datasets_by_type.items():
            if not datasets:
                continue

            emoji, display_name = type_display.get(dtype, ("ğŸ“Š", dtype.title()))
            lines.append(f"### {emoji} {display_name}")
            lines.append("")
            lines.append("| æ•°æ®é›† | å‘å¸ƒè€… | ä¸‹è½½é‡ | ä¿¡å· |")
            lines.append("|--------|--------|--------|------|")

            for ds in datasets[:limit]:
                ds_id = ds.get("id", ds.get("name", "Unknown"))
                ds_name = ds_id.split("/")[-1] if "/" in ds_id else ds_id
                author = ds_id.split("/")[0] if "/" in ds_id else "-"
                downloads = ds.get("downloads", 0)

                # Get signals from classification
                classification = ds.get("_classification", {})
                all_types = classification.get("all_types", [])
                signals = []
                for t in all_types[:2]:
                    if t.get("keyword_matches"):
                        signals.extend(t["keyword_matches"][:2])
                signal_str = ", ".join(signals[:3]) if signals else "-"

                lines.append(f"| [{ds_name}](https://huggingface.co/datasets/{ds_id}) | {author} | {downloads:,} | {signal_str} |")

            lines.append("")

        if not any(datasets_by_type.values()):
            lines.append("*æœ¬å‘¨æ— æ–°çš„é«˜ä»·å€¼æ•°æ®é›†*")
            lines.append("")

        return lines

    def _generate_papers_section(self, papers: list[dict]) -> list[str]:
        """Generate papers section."""
        lines = []
        lines.append("## ğŸ“„ ç›¸å…³è®ºæ–‡ï¼ˆè®­ç»ƒæ•°æ®æ–¹æ³•è®ºï¼‰")
        lines.append("")

        if not papers:
            lines.append("*æœ¬å‘¨æ— ç›¸å…³è®ºæ–‡*")
            lines.append("")
            return lines

        limit = self.limits.get("papers", 15)

        lines.append("| è®ºæ–‡ | å…³é”®è¯ | é“¾æ¥ |")
        lines.append("|------|--------|------|")

        for paper in papers[:limit]:
            title = paper.get("title", "Unknown")[:60]
            if len(paper.get("title", "")) > 60:
                title += "..."

            # Extract keywords
            keywords = paper.get("_matched_keywords", [])[:3]
            kw_str = ", ".join(keywords) if keywords else "-"

            # Get link
            arxiv_id = paper.get("arxiv_id", paper.get("id", ""))
            if arxiv_id:
                link = f"[arXiv]({paper.get('url', f'https://arxiv.org/abs/{arxiv_id}')})"
            else:
                link = paper.get("url", "-")

            lines.append(f"| {title} | {kw_str} | {link} |")

        lines.append("")
        return lines

    def generate_console_summary(
        self,
        lab_activity: dict,
        vendor_activity: dict,
        datasets_by_type: dict,
    ) -> str:
        """Generate a brief console summary.

        Args:
            lab_activity: Activity from AI labs.
            vendor_activity: Activity from data vendors.
            datasets_by_type: Datasets grouped by type.

        Returns:
            Console-friendly summary text.
        """
        lines = []
        lines.append("=" * 60)
        lines.append("  AI Dataset Radar - ç«äº‰æƒ…æŠ¥æ‘˜è¦")
        lines.append("=" * 60)
        lines.append("")

        # Labs summary
        labs = lab_activity.get("labs", {})
        for category, category_name in [
            ("frontier_labs", "Frontier Labs"),
            ("emerging_labs", "Emerging Labs"),
            ("research_labs", "Research Labs"),
        ]:
            cat_data = labs.get(category, {})
            active = [k for k, v in cat_data.items() if v.get("datasets") or v.get("models")]
            if active:
                lines.append(f"  {category_name}: {', '.join(active[:5])}")

        # Vendors summary
        vendors = vendor_activity.get("vendors", {})
        active_vendors = []
        for tier_data in vendors.values():
            for v_name, v_data in tier_data.items():
                if v_data.get("datasets"):
                    active_vendors.append(v_name)
        if active_vendors:
            lines.append(f"  Active Vendors: {', '.join(active_vendors[:5])}")

        # Type summary
        lines.append("")
        lines.append("  æ•°æ®é›†ç±»å‹åˆ†å¸ƒ:")
        for dtype, datasets in datasets_by_type.items():
            if datasets:
                lines.append(f"    {dtype}: {len(datasets)}")

        lines.append("")
        lines.append("=" * 60)

        return "\n".join(lines)
