<p align="center">
  <h1 align="center">ğŸ›°ï¸ AI Dataset Radar</h1>
  <p align="center">
    <strong>Track AI training datasets across HuggingFace, GitHub, arXiv & blogs</strong>
  </p>
  <p align="center">
    <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
    <a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.10+-blue.svg" alt="Python 3.10+"></a>
    <a href="#mcp-server"><img src="https://img.shields.io/badge/MCP-Server-purple.svg" alt="MCP Server"></a>
  </p>
</p>

---

Monitor 30+ AI labs and data vendors. Get structured reports on new datasets, GitHub repos, papers, and blog posts â€” delivered as Markdown for humans or JSON for LLMs.

## âœ¨ What You Get

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  12 datasets â”‚ 138 repos â”‚ 28 papers â”‚ 4 blog posts            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ OpenAI, Anthropic, Google, Meta, DeepSeek, Qwen...          â”‚
â”‚  â€¢ Scale AI, Argilla, Snorkel, Labelbox...                     â”‚
â”‚  â€¢ RLHF, SFT, Synthetic, Agent, Evaluation datasets            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Option 1: Command Line

```bash
git clone https://github.com/liuxiaotong/ai-dataset-radar.git
cd ai-dataset-radar
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Run scan
python src/main_intel.py --days 7
```

Reports saved to `data/reports/`:
- `intel_report_2024-01-15.md` â€” Human-readable
- `intel_report_2024-01-15.json` â€” For LLMs/scripts

### Option 2: Claude Desktop (MCP)

Add to `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "ai-dataset-radar": {
      "command": "/path/to/ai-dataset-radar/.venv/bin/python",
      "args": ["/path/to/ai-dataset-radar/mcp_server/server.py"]
    }
  }
}
```

Then ask Claude: *"Scan for new AI datasets"* or *"What's new from OpenAI?"*

### Option 3: Claude Code

```bash
/radar    # Get project context
/scan     # Run intelligence scan
```

---

## ğŸ“Š Output Example

### JSON (for LLMs)

```json
{
  "summary": {
    "total_datasets": 12,
    "total_github_repos": 138,
    "total_github_repos_high_relevance": 2,
    "total_papers": 28
  },
  "datasets": [
    {
      "id": "google/WaxalNLP",
      "category": "multilingual",
      "downloads": 1539,
      "license": "cc-by-4.0",
      "signals": ["multilingual", "audio"]
    }
  ],
  "github_activity": [
    {
      "org": "argilla-io",
      "repos_updated": [
        {"name": "argilla", "relevance": "high", "relevance_signals": ["annotation", "rlhf"]}
      ]
    }
  ]
}
```

### Markdown (for humans)

```markdown
## AI Labs Activity

### google_deepmind
- **WaxalNLP** (1.5K downloads) - ASR/TTS for African languages

## GitHub Activity
### argilla-io
- **argilla** â­ 8.2K [HIGH] - Data curation for LLMs
```

---

## âš™ï¸ Configuration

Edit `config.yaml` to customize:

```yaml
# Organizations to monitor
watched_orgs:
  frontier_labs:
    openai: { hf_ids: ["openai"], keywords: ["gpt"] }
    anthropic: { hf_ids: ["anthropic"], keywords: ["claude"] }
  china_opensource:
    qwen: { hf_ids: ["Qwen"], keywords: ["qwen"] }
    deepseek: { hf_ids: ["deepseek-ai"], keywords: ["deepseek"] }

# Data types to track
priority_data_types:
  preference: { keywords: ["rlhf", "dpo", "preference"] }
  sft: { keywords: ["instruction", "chat", "alpaca"] }
  agent: { keywords: ["tool use", "function calling"] }

# GitHub relevance keywords
sources:
  github:
    relevance_keywords: [dataset, annotation, benchmark, rlhf]
```

**Optional:** Set `GITHUB_TOKEN` for higher API rate limits.

---

## ğŸ—ï¸ Architecture

```
ai-dataset-radar/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main_intel.py      # Entry point
â”‚   â”œâ”€â”€ scrapers/          # HuggingFace, GitHub, arXiv, RSS
â”‚   â”œâ”€â”€ trackers/          # Org & blog monitors
â”‚   â”œâ”€â”€ analyzers/         # Dataset classification
â”‚   â””â”€â”€ output_formatter.py
â”œâ”€â”€ mcp_server/            # Claude Desktop integration
â”‚   â””â”€â”€ server.py
â”œâ”€â”€ .claude/commands/      # Claude Code skills
â”‚   â”œâ”€â”€ radar.md
â”‚   â””â”€â”€ scan.md
â”œâ”€â”€ config.yaml            # Watchlist configuration
â””â”€â”€ data/reports/          # Generated reports
```

---

## ğŸ”Œ MCP Server Tools

When using Claude Desktop:

| Tool | Description |
|------|-------------|
| `radar_scan` | Run full intelligence scan |
| `radar_summary` | Get latest report summary |
| `radar_datasets` | List datasets (filter by category) |
| `radar_github` | View GitHub activity (filter by relevance) |
| `radar_papers` | View recent papers |
| `radar_config` | Show current watchlist |

---

## ğŸ“¦ Dataset Categories

| Category | Examples |
|----------|----------|
| **SFT** | Alpaca, ShareGPT, OpenOrca |
| **Preference** | UltraFeedback, HelpSteer, HH-RLHF |
| **Synthetic** | Sera, Magpie |
| **Agent** | SWE-bench, WebArena, ToolBench |
| **Evaluation** | MMLU, HumanEval, GPQA |
| **Multimodal** | Action100M, VoxPopuli |
| **Code** | StarCoder, CodeParrot |

---

## ğŸ§ª Development

```bash
# Run tests
python -m pytest tests/ -v

# Add a new scraper
# 1. Create src/scrapers/my_source.py
# 2. Inherit from BaseScraper
# 3. Register with @register_scraper("my_source")
```

<details>
<summary>Example: Custom Scraper</summary>

```python
from src.scrapers.base import BaseScraper
from src.scrapers.registry import register_scraper

@register_scraper("my_source")
class MySourceScraper(BaseScraper):
    name = "my_source"
    source_type = "dataset_registry"

    def scrape(self, config=None) -> list[dict]:
        return [{"source": "my_source", "id": "dataset-1"}]
```

</details>

---

## ğŸ—ºï¸ Roadmap

- [x] Multi-source aggregation (HF, GitHub, arXiv, blogs)
- [x] Dual output (Markdown + JSON)
- [x] MCP Server for Claude Desktop
- [x] Claude Code skills
- [ ] Scheduled execution & alerts
- [ ] Web dashboard
- [ ] LLM-powered summarization

---

## ğŸ¤ Contributing

PRs welcome! Areas where help is needed:

- New data sources (e.g., Twitter/X, Discord)
- Improved classification heuristics
- Web UI
- Documentation translations

---

## ğŸ“„ License

MIT â€” see [LICENSE](LICENSE)

---

<p align="center">
  <sub>Built for the AI data community. Star â­ if useful!</sub>
</p>
