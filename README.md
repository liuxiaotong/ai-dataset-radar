<p align="center">
  <h1 align="center">ğŸ›°ï¸ AI Dataset Radar</h1>
  <p align="center">
    <strong>Track AI training datasets across HuggingFace, GitHub, arXiv & blogs</strong><br>
    <strong>è¿½è¸ª HuggingFaceã€GitHubã€arXiv å’Œåšå®¢ä¸Šçš„ AI è®­ç»ƒæ•°æ®é›†</strong>
  </p>
  <p align="center">
    <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
    <a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.10+-blue.svg" alt="Python 3.10+"></a>
    <a href="#mcp-server"><img src="https://img.shields.io/badge/MCP-Server-purple.svg" alt="MCP Server"></a>
  </p>
  <p align="center">
    <a href="#-quick-start">English</a> | <a href="#-å¿«é€Ÿå¼€å§‹">ä¸­æ–‡</a>
  </p>
</p>

---

Monitor 30+ AI labs and data vendors. Get structured reports on new datasets, GitHub repos, papers, and blog posts â€” delivered as Markdown for humans or JSON for LLMs.

ç›‘æ§ 30+ AI å®éªŒå®¤å’Œæ•°æ®ä¾›åº”å•†ã€‚è·å–æ–°æ•°æ®é›†ã€GitHub ä»“åº“ã€è®ºæ–‡å’Œåšå®¢æ–‡ç« çš„ç»“æ„åŒ–æŠ¥å‘Š â€” æ”¯æŒ Markdownï¼ˆäººç±»å¯è¯»ï¼‰å’Œ JSONï¼ˆä¾› LLM ä½¿ç”¨ï¼‰åŒæ ¼å¼è¾“å‡ºã€‚

## âœ¨ What You Get / åŠŸèƒ½æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  12 datasets â”‚ 138 repos â”‚ 28 papers â”‚ 4 blog posts            â”‚
â”‚  12 ä¸ªæ•°æ®é›† â”‚ 138 ä¸ªä»“åº“ â”‚ 28 ç¯‡è®ºæ–‡ â”‚ 4 ç¯‡åšå®¢                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ OpenAI, Anthropic, Google, Meta, DeepSeek, Qwen...          â”‚
â”‚  â€¢ Scale AI, Argilla, Snorkel, Labelbox...                     â”‚
â”‚  â€¢ RLHF, SFT, Synthetic, Agent, Evaluation datasets            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Option 1: Command Line

```bash
git clone https://github.com/liuxiaotong/ai-dataset-radar.git
cd ai-dataset-radar
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Run scan
python src/main_intel.py --days 7
```

Reports saved to `data/reports/`:
- `intel_report_YYYY-MM-DD.md` â€” Human-readable
- `intel_report_YYYY-MM-DD.json` â€” For LLMs/scripts

### Option 2: Claude Desktop (MCP)

Add to `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "ai-dataset-radar": {
      "command": "/path/to/ai-dataset-radar/.venv/bin/python",
      "args": ["/path/to/ai-dataset-radar/mcp_server/server.py"]
    }
  }
}
```

Then ask Claude: *"Scan for new AI datasets"* or *"What's new from OpenAI?"*

### Option 3: Claude Code

```bash
/radar    # Get project context
/scan     # Run intelligence scan
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šå‘½ä»¤è¡Œ

```bash
git clone https://github.com/liuxiaotong/ai-dataset-radar.git
cd ai-dataset-radar
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# è¿è¡Œæ‰«æ
python src/main_intel.py --days 7
```

æŠ¥å‘Šä¿å­˜åœ¨ `data/reports/`:
- `intel_report_YYYY-MM-DD.md` â€” äººç±»å¯è¯»
- `intel_report_YYYY-MM-DD.json` â€” ä¾› LLM/è„šæœ¬ä½¿ç”¨

### æ–¹å¼äºŒï¼šClaude Desktop (MCP)

ç¼–è¾‘ `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "ai-dataset-radar": {
      "command": "/ä½ çš„è·¯å¾„/ai-dataset-radar/.venv/bin/python",
      "args": ["/ä½ çš„è·¯å¾„/ai-dataset-radar/mcp_server/server.py"]
    }
  }
}
```

ç„¶ååœ¨ Claude ä¸­è¯´ï¼š*"æ‰«ææ–°çš„ AI æ•°æ®é›†"* æˆ– *"OpenAI æœ€è¿‘æœ‰ä»€ä¹ˆæ–°åŠ¨æ€ï¼Ÿ"*

### æ–¹å¼ä¸‰ï¼šClaude Code

```bash
/radar    # è·å–é¡¹ç›®ä¸Šä¸‹æ–‡
/scan     # è¿è¡Œæƒ…æŠ¥æ‰«æ
```

---

## ğŸ“Š Output Example / è¾“å‡ºç¤ºä¾‹

### JSON (for LLMs / ä¾› LLM ä½¿ç”¨)

```json
{
  "summary": {
    "total_datasets": 12,
    "total_github_repos": 138,
    "total_github_repos_high_relevance": 2,
    "total_papers": 28
  },
  "datasets": [
    {
      "id": "google/WaxalNLP",
      "category": "multilingual",
      "downloads": 1539,
      "license": "cc-by-4.0",
      "signals": ["multilingual", "audio"]
    }
  ],
  "github_activity": [
    {
      "org": "argilla-io",
      "repos_updated": [
        {"name": "argilla", "relevance": "high", "relevance_signals": ["annotation", "rlhf"]}
      ]
    }
  ]
}
```

### Markdown (for humans / äººç±»å¯è¯»)

```markdown
## AI Labs Activity / AI å®éªŒå®¤åŠ¨æ€

### google_deepmind
- **WaxalNLP** (1.5K downloads) - ASR/TTS for African languages

## GitHub Activity / GitHub æ´»åŠ¨
### argilla-io
- **argilla** â­ 8.2K [HIGH] - Data curation for LLMs
```

---

## âš™ï¸ Configuration / é…ç½®

Edit `config.yaml` to customize / ç¼–è¾‘ `config.yaml` è‡ªå®šä¹‰é…ç½®:

```yaml
# Organizations to monitor / ç›‘æ§çš„ç»„ç»‡
watched_orgs:
  frontier_labs:                    # ä¸€çº¿å®éªŒå®¤
    openai: { hf_ids: ["openai"], keywords: ["gpt"] }
    anthropic: { hf_ids: ["anthropic"], keywords: ["claude"] }
  china_opensource:                 # ä¸­å›½å¼€æºå¤§æ¨¡å‹
    qwen: { hf_ids: ["Qwen"], keywords: ["qwen"] }
    deepseek: { hf_ids: ["deepseek-ai"], keywords: ["deepseek"] }

# Data types to track / å…³æ³¨çš„æ•°æ®ç±»å‹
priority_data_types:
  preference: { keywords: ["rlhf", "dpo", "preference"] }
  sft: { keywords: ["instruction", "chat", "alpaca"] }
  agent: { keywords: ["tool use", "function calling"] }

# GitHub relevance keywords / GitHub ç›¸å…³æ€§å…³é”®è¯
sources:
  github:
    relevance_keywords: [dataset, annotation, benchmark, rlhf]
```

**Optional / å¯é€‰:** Set `GITHUB_TOKEN` for higher API rate limits / è®¾ç½® `GITHUB_TOKEN` è·å¾—æ›´é«˜çš„ API é€Ÿç‡é™åˆ¶ã€‚

---

## ğŸ—ï¸ Architecture / æ¶æ„

```
ai-dataset-radar/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main_intel.py        # Entry point / å…¥å£
â”‚   â”œâ”€â”€ scrapers/            # HuggingFace, GitHub, arXiv, RSS
â”‚   â”œâ”€â”€ trackers/            # Org & blog monitors / ç»„ç»‡å’Œåšå®¢ç›‘æ§
â”‚   â”œâ”€â”€ analyzers/           # Dataset classification / æ•°æ®é›†åˆ†ç±»
â”‚   â””â”€â”€ output_formatter.py  # Dual output / åŒæ ¼å¼è¾“å‡º
â”œâ”€â”€ mcp_server/              # Claude Desktop integration / Claude Desktop é›†æˆ
â”‚   â””â”€â”€ server.py
â”œâ”€â”€ .claude/commands/        # Claude Code skills / Claude Code æŠ€èƒ½
â”‚   â”œâ”€â”€ radar.md
â”‚   â””â”€â”€ scan.md
â”œâ”€â”€ config.yaml              # Watchlist configuration / ç›‘æ§é…ç½®
â””â”€â”€ data/reports/            # Generated reports / ç”Ÿæˆçš„æŠ¥å‘Š
```

---

## ğŸ”Œ MCP Server Tools / MCP æœåŠ¡å™¨å·¥å…·

When using Claude Desktop / åœ¨ Claude Desktop ä¸­ä½¿ç”¨:

| Tool / å·¥å…· | Description / æè¿° |
|-------------|-------------------|
| `radar_scan` | Run full scan / è¿è¡Œå®Œæ•´æ‰«æ |
| `radar_summary` | Get report summary / è·å–æŠ¥å‘Šæ‘˜è¦ |
| `radar_datasets` | List datasets (filter by category) / åˆ—å‡ºæ•°æ®é›†ï¼ˆæŒ‰ç±»å‹è¿‡æ»¤ï¼‰ |
| `radar_github` | View GitHub activity (filter by relevance) / æŸ¥çœ‹ GitHub æ´»åŠ¨ï¼ˆæŒ‰ç›¸å…³æ€§è¿‡æ»¤ï¼‰ |
| `radar_papers` | View recent papers / æŸ¥çœ‹æœ€æ–°è®ºæ–‡ |
| `radar_config` | Show current watchlist / æ˜¾ç¤ºå½“å‰ç›‘æ§é…ç½® |

---

## ğŸ“¦ Dataset Categories / æ•°æ®é›†ç±»å‹

| Category / ç±»å‹ | Examples / ç¤ºä¾‹ | Description / æè¿° |
|----------------|-----------------|-------------------|
| **SFT** | Alpaca, ShareGPT, OpenOrca | Instruction-following / æŒ‡ä»¤è·Ÿéš |
| **Preference** | UltraFeedback, HelpSteer, HH-RLHF | RLHF/DPO training / RLHF/DPO è®­ç»ƒ |
| **Synthetic** | Sera, Magpie | AI-generated / AI ç”Ÿæˆ |
| **Agent** | SWE-bench, WebArena, ToolBench | Tool use / å·¥å…·ä½¿ç”¨ |
| **Evaluation** | MMLU, HumanEval, GPQA | Benchmarks / åŸºå‡†æµ‹è¯• |
| **Multimodal** | Action100M, VoxPopuli | Image/Audio/Video / å¤šæ¨¡æ€ |
| **Code** | StarCoder, CodeParrot | Programming / ç¼–ç¨‹ |

---

## ğŸ¯ Organizations Tracked / ç›‘æ§çš„ç»„ç»‡

| Category / ç±»åˆ« | Organizations / ç»„ç»‡ |
|----------------|---------------------|
| **Frontier Labs / ä¸€çº¿å®éªŒå®¤** | OpenAI, Anthropic, Google/DeepMind, Meta, xAI |
| **Emerging Labs / æ–°å…´å®éªŒå®¤** | Mistral, Cohere, AI21, Together, Databricks |
| **Research Labs / ç ”ç©¶æœºæ„** | EleutherAI, HuggingFace, Allen AI, LMSys, NVIDIA |
| **China Open Source / ä¸­å›½å¼€æº** | Qwen, DeepSeek, ChatGLM, Baichuan, Yi, InternLM |
| **China Closed Source / ä¸­å›½é—­æº** | Baidu ERNIE, ByteDance Doubao, Tencent Hunyuan, Moonshot Kimi |
| **Data Vendors / æ•°æ®ä¾›åº”å•†** | Scale AI, Surge AI, Argilla, Snorkel, Labelbox |

---

## ğŸ§ª Development / å¼€å‘

```bash
# Run tests / è¿è¡Œæµ‹è¯•
python -m pytest tests/ -v

# Add a new scraper / æ·»åŠ æ–°çˆ¬è™«
# 1. Create src/scrapers/my_source.py / åˆ›å»ºæ–‡ä»¶
# 2. Inherit from BaseScraper / ç»§æ‰¿ BaseScraper
# 3. Register with @register_scraper("my_source") / æ³¨å†Œ
```

<details>
<summary>Example: Custom Scraper / ç¤ºä¾‹ï¼šè‡ªå®šä¹‰çˆ¬è™«</summary>

```python
from src.scrapers.base import BaseScraper
from src.scrapers.registry import register_scraper

@register_scraper("my_source")
class MySourceScraper(BaseScraper):
    name = "my_source"
    source_type = "dataset_registry"

    def scrape(self, config=None) -> list[dict]:
        return [{"source": "my_source", "id": "dataset-1"}]
```

</details>

---

## ğŸ—ºï¸ Roadmap / è·¯çº¿å›¾

- [x] Multi-source aggregation / å¤šæºèšåˆ (HF, GitHub, arXiv, blogs)
- [x] Dual output / åŒæ ¼å¼è¾“å‡º (Markdown + JSON)
- [x] MCP Server for Claude Desktop / Claude Desktop MCP æœåŠ¡å™¨
- [x] Claude Code skills / Claude Code æŠ€èƒ½
- [ ] Scheduled execution & alerts / å®šæ—¶æ‰§è¡Œå’Œå‘Šè­¦
- [ ] Web dashboard / Web æ§åˆ¶å°
- [ ] LLM-powered summarization / LLM é©±åŠ¨çš„æ‘˜è¦

---

## ğŸ¤ Contributing / è´¡çŒ®

PRs welcome! Areas where help is needed / æ¬¢è¿ PRï¼éœ€è¦å¸®åŠ©çš„é¢†åŸŸ:

- New data sources / æ–°æ•°æ®æº (e.g., Twitter/X, Discord)
- Improved classification heuristics / æ”¹è¿›åˆ†ç±»ç®—æ³•
- Web UI / Web ç•Œé¢
- Documentation translations / æ–‡æ¡£ç¿»è¯‘

---

## ğŸ“„ License / è®¸å¯è¯

MIT â€” see [LICENSE](LICENSE)

---

<p align="center">
  <sub>Built for the AI data community. Star â­ if useful!</sub><br>
  <sub>ä¸º AI æ•°æ®ç¤¾åŒºè€Œå»ºã€‚å¦‚æœæœ‰ç”¨è¯·ç‚¹ä¸ªæ˜Ÿ â­</sub>
</p>
