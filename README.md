# AI Dataset Radar

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

**A Multi-Signal Intelligence System for High-Value AI Dataset Discovery**

**é¢å‘é«˜ä»·å€¼ AI æ•°æ®é›†å‘ç°çš„å¤šä¿¡å·æƒ…æŠ¥ç³»ç»Ÿ**

---

## Abstract | æ‘˜è¦

AI Dataset Radar is an automated intelligence system designed to identify and evaluate high-value datasets for machine learning research and development. The system aggregates heterogeneous signals from multiple authoritative sourcesâ€”including citation metrics, model adoption patterns, and benchmark associationsâ€”to compute composite value scores that quantify a dataset's research impact, adoption trajectory, and commercial potential.

AI Dataset Radar æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–æƒ…æŠ¥ç³»ç»Ÿï¼Œæ—¨åœ¨è¯†åˆ«å’Œè¯„ä¼°æœºå™¨å­¦ä¹ ç ”ç©¶ä¸å¼€å‘ä¸­çš„é«˜ä»·å€¼æ•°æ®é›†ã€‚è¯¥ç³»ç»Ÿèšåˆæ¥è‡ªå¤šä¸ªæƒå¨æ¥æºçš„å¼‚æ„ä¿¡å·â€”â€”åŒ…æ‹¬å¼•ç”¨æŒ‡æ ‡ã€æ¨¡å‹é‡‡ç”¨æ¨¡å¼å’ŒåŸºå‡†å…³è”â€”â€”è®¡ç®—ç»¼åˆä»·å€¼è¯„åˆ†ï¼Œä»¥é‡åŒ–æ•°æ®é›†çš„ç ”ç©¶å½±å“åŠ›ã€é‡‡ç”¨è½¨è¿¹å’Œå•†ä¸šæ½œåŠ›ã€‚

**Key Contributions | ä¸»è¦è´¡çŒ®:**

1. A weighted multi-factor scoring model integrating six orthogonal signals for dataset valuation
2. Specialized filtering mechanisms for post-training datasets (SFT, RLHF, Agent, Evaluation)
3. Organization-level competitive intelligence tracking across 20+ research institutions
4. Temporal signal analysis distinguishing leading indicators from lagging metrics

---

## 1. Introduction | å¼•è¨€

The proliferation of AI research has created an information asymmetry problem: while thousands of datasets are published annually, identifying those with high research impact or commercial value remains challenging. Traditional discovery methodsâ€”keyword search, manual curationâ€”fail to capture emerging trends or quantify relative value.

AI ç ”ç©¶çš„å¿«é€Ÿå‘å±•é€ æˆäº†ä¿¡æ¯ä¸å¯¹ç§°é—®é¢˜ï¼šå°½ç®¡æ¯å¹´å‘å¸ƒæ•°åƒä¸ªæ•°æ®é›†ï¼Œä½†è¯†åˆ«å…·æœ‰é«˜ç ”ç©¶å½±å“åŠ›æˆ–å•†ä¸šä»·å€¼çš„æ•°æ®é›†ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¼ ç»Ÿå‘ç°æ–¹æ³•â€”â€”å…³é”®è¯æœç´¢ã€äººå·¥ç­›é€‰â€”â€”æ— æ³•æ•æ‰æ–°å…´è¶‹åŠ¿æˆ–é‡åŒ–ç›¸å¯¹ä»·å€¼ã€‚

This system addresses three fundamental questions:
- **What datasets are gaining research traction?** (Citation velocity analysis)
- **Which datasets power production models?** (Model card reverse-engineering)
- **Where are annotation opportunities?** (Post-training data demand signals)

æœ¬ç³»ç»Ÿè§£å†³ä¸‰ä¸ªåŸºæœ¬é—®é¢˜ï¼š
- **å“ªäº›æ•°æ®é›†æ­£åœ¨è·å¾—ç ”ç©¶å…³æ³¨ï¼Ÿ**ï¼ˆå¼•ç”¨å¢é€Ÿåˆ†æï¼‰
- **å“ªäº›æ•°æ®é›†æ”¯æ’‘ç”Ÿäº§æ¨¡å‹ï¼Ÿ**ï¼ˆæ¨¡å‹å¡é€†å‘å·¥ç¨‹ï¼‰
- **å“ªé‡Œå­˜åœ¨æ ‡æ³¨æœºä¼šï¼Ÿ**ï¼ˆåè®­ç»ƒæ•°æ®éœ€æ±‚ä¿¡å·ï¼‰

---

## 2. Methodology | æ–¹æ³•è®º

### 2.1 Value Scoring Framework | ä»·å€¼è¯„åˆ†æ¡†æ¶

The system employs a weighted additive scoring model (Score âˆˆ [0, 100]):

ç³»ç»Ÿé‡‡ç”¨åŠ æƒåŠ æ³•è¯„åˆ†æ¨¡å‹ï¼ˆè¯„åˆ† âˆˆ [0, 100]ï¼‰ï¼š

```
Score = Î£ (weight_i Ã— indicator_i)
```

**English:**

| Signal | Weight | Criterion | Rationale |
|--------|--------|-----------|-----------|
| SOTA Model Usage | 30 | Referenced by state-of-the-art models | Indicates benchmark relevance |
| Citation Velocity | 20 | Monthly citation growth â‰¥ 10 | Leading indicator of research interest |
| Model Adoption | 20 | Used by â‰¥ 3 HuggingFace models | Proxy for practical utility |
| Institution Prestige | 15 | Origin: top-tier research labs | Quality signal |
| Reproducibility | 10 | Associated paper + code available | Scientific rigor |
| Scale | 5 | Dataset size > 10GB | Resource investment indicator |

**ä¸­æ–‡:**

| ä¿¡å· | æƒé‡ | æ ‡å‡† | ä¾æ® |
|------|------|------|------|
| SOTA æ¨¡å‹ä½¿ç”¨ | 30 | è¢« SOTA æ¨¡å‹å¼•ç”¨ | è¡¨æ˜åŸºå‡†ç›¸å…³æ€§ |
| å¼•ç”¨å¢é€Ÿ | 20 | æœˆå¼•ç”¨å¢é•¿ â‰¥ 10 | ç ”ç©¶å…´è¶£çš„é¢†å…ˆæŒ‡æ ‡ |
| æ¨¡å‹é‡‡ç”¨åº¦ | 20 | è¢« â‰¥ 3 ä¸ª HuggingFace æ¨¡å‹ä½¿ç”¨ | å®ç”¨æ€§ä»£ç†æŒ‡æ ‡ |
| æœºæ„å£°èª‰ | 15 | æ¥æºï¼šé¡¶çº§ç ”ç©¶å®éªŒå®¤ | è´¨é‡ä¿¡å· |
| å¯å¤ç°æ€§ | 10 | æœ‰é…å¥—è®ºæ–‡å’Œä»£ç  | ç§‘å­¦ä¸¥è°¨æ€§ |
| è§„æ¨¡ | 5 | æ•°æ®é›†å¤§å° > 10GB | èµ„æºæŠ•å…¥æŒ‡æ ‡ |

### 2.2 Post-Training Dataset Classification | åè®­ç»ƒæ•°æ®é›†åˆ†ç±»

A specialized `PostTrainingFilter` module classifies datasets into four categories critical for LLM development:

ä¸“é—¨çš„ `PostTrainingFilter` æ¨¡å—å°†æ•°æ®é›†åˆ†ç±»ä¸º LLM å¼€å‘çš„å››ä¸ªå…³é”®ç±»åˆ«ï¼š

**English:**

| Category | Description | Example Datasets |
|----------|-------------|------------------|
| **SFT** (Supervised Fine-Tuning) | Instruction-following data | Alpaca, ShareGPT, OpenOrca, FLAN |
| **Preference** (RLHF/DPO) | Human preference pairs | UltraFeedback, HelpSteer, Nectar, HH-RLHF |
| **Agent** | Tool use and trajectory data | WebArena, SWE-bench, ToolBench, GAIA |
| **Evaluation** | Benchmark test sets | MMLU, HumanEval, GPQA, GSM8K |

**ä¸­æ–‡:**

| ç±»åˆ« | æè¿° | ç¤ºä¾‹æ•°æ®é›† |
|------|------|-----------|
| **SFT** (ç›‘ç£å¾®è°ƒ) | æŒ‡ä»¤éµå¾ªæ•°æ® | Alpaca, ShareGPT, OpenOrca, FLAN |
| **Preference** (RLHF/DPO) | äººç±»åå¥½é…å¯¹ | UltraFeedback, HelpSteer, Nectar, HH-RLHF |
| **Agent** | å·¥å…·ä½¿ç”¨å’Œè½¨è¿¹æ•°æ® | WebArena, SWE-bench, ToolBench, GAIA |
| **Evaluation** | åŸºå‡†æµ‹è¯•é›† | MMLU, HumanEval, GPQA, GSM8K |

Classification employs a confidence-weighted signal matching approach:

åˆ†ç±»é‡‡ç”¨ç½®ä¿¡åº¦åŠ æƒä¿¡å·åŒ¹é…æ–¹æ³•ï¼š

```
Confidence Score = 0.6 Ã— |strong_signals| + 0.3 Ã— |medium_signals| + 0.1 Ã— |weak_signals|
```

### 2.3 Temporal Signal Analysis | æ—¶åºä¿¡å·åˆ†æ

**English:**

| Signal Type | Source | Temporal Characteristic | Business Implication |
|-------------|--------|------------------------|---------------------|
| Citation Velocity | Semantic Scholar | Leading (6-12 months) | Predicts future industry demand |
| Model Adoption | HuggingFace | Concurrent | Reflects current production use |
| SOTA Association | Benchmarks | Concurrent | Indicates premium positioning |

**ä¸­æ–‡:**

| ä¿¡å·ç±»å‹ | æ¥æº | æ—¶åºç‰¹å¾ | å•†ä¸šå«ä¹‰ |
|----------|------|----------|----------|
| å¼•ç”¨å¢é€Ÿ | Semantic Scholar | é¢†å…ˆï¼ˆ6-12ä¸ªæœˆï¼‰ | é¢„æµ‹æœªæ¥äº§ä¸šéœ€æ±‚ |
| æ¨¡å‹é‡‡ç”¨ | HuggingFace | åŒæ­¥ | åæ˜ å½“å‰ç”Ÿäº§ä½¿ç”¨ |
| SOTA å…³è” | åŸºå‡†æµ‹è¯• | åŒæ­¥ | è¡¨æ˜æº¢ä»·å®šä½ |

---

## 3. System Architecture | ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI Dataset Radar                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Semantic   â”‚  â”‚ HuggingFace â”‚  â”‚   GitHub    â”‚   Data      â”‚
â”‚  â”‚  Scholar    â”‚  â”‚  Hub API    â”‚  â”‚  Trending   â”‚   Sources   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                â”‚                â”‚                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                          â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Scraper Layer                          â”‚ â”‚
â”‚  â”‚  semantic_scholar.py â”‚ huggingface.py â”‚ github.py â”‚ arxiv â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   Analysis Layer                          â”‚ â”‚
â”‚  â”‚  ValueScorer â”‚ PostTrainingFilter â”‚ TrendAnalyzer â”‚ Opps  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚               Persistence & Reporting                     â”‚ â”‚
â”‚  â”‚          SQLite DB â”‚ Markdown Reports â”‚ JSON Export       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.1 Data Sources | æ•°æ®æ¥æº

**English:**

| Source | Update Frequency | Content Type | API Requirements |
|--------|------------------|--------------|------------------|
| Semantic Scholar | Real-time | Citation metrics, paper metadata | API key recommended |
| HuggingFace Hub | 1-3 days | Datasets, models, papers | Public API |
| GitHub Trending | 1-3 days | Repository metadata | Token optional |
| arXiv | 7-14 days | Preprint papers | Public feed |

**ä¸­æ–‡:**

| æ¥æº | æ›´æ–°é¢‘ç‡ | å†…å®¹ç±»å‹ | API è¦æ±‚ |
|------|----------|----------|----------|
| Semantic Scholar | å®æ—¶ | å¼•ç”¨æŒ‡æ ‡ã€è®ºæ–‡å…ƒæ•°æ® | å»ºè®®é…ç½® API Key |
| HuggingFace Hub | 1-3 å¤© | æ•°æ®é›†ã€æ¨¡å‹ã€è®ºæ–‡ | å…¬å¼€ API |
| GitHub Trending | 1-3 å¤© | ä»“åº“å…ƒæ•°æ® | Token å¯é€‰ |
| arXiv | 7-14 å¤© | é¢„å°æœ¬è®ºæ–‡ | å…¬å¼€ Feed |

### 3.2 Organization Tracking | ç»„ç»‡è¿½è¸ª

The system monitors dataset publications from 20+ organizations:

ç³»ç»Ÿç›‘æ§ 20+ ç»„ç»‡çš„æ•°æ®é›†å‘å¸ƒï¼š

**Technology Companies | ç§‘æŠ€å…¬å¸:**
Google/DeepMind, OpenAI, Meta/FAIR, ByteDance, Alibaba, Tencent, Baidu, Huawei

**Research Laboratories | ç ”ç©¶å®éªŒå®¤:**
Anthropic, Mistral, DeepSeek, LMSys, EleutherAI, Allen AI, UC Berkeley, Stanford, NVIDIA, Hugging Face

---

## 4. Installation | å®‰è£…

### 4.1 Requirements | ç¯å¢ƒè¦æ±‚

- Python 3.8+
- SQLite 3.35+
- 512 MB available memory

### 4.2 Setup | é…ç½®

```bash
git clone https://github.com/liuxiaotong/ai-dataset-radar.git
cd ai-dataset-radar

python -m venv venv
source venv/bin/activate  # Linux/macOS
# or: venv\Scripts\activate  # Windows

pip install -r requirements.txt
```

### 4.3 API Configuration | API é…ç½®

```bash
# Semantic Scholar API (recommended for citation analysis)
# ç”³è¯·åœ°å€: https://www.semanticscholar.org/product/api
export SEMANTIC_SCHOLAR_API_KEY=your_key_here

# GitHub API (optional, for higher rate limits)
export GITHUB_TOKEN=your_token_here
```

**Rate Limits | é€Ÿç‡é™åˆ¶:**

| Service | Without Key | With Key |
|---------|-------------|----------|
| Semantic Scholar | 100 req / 5 min | 1 req / sec |
| GitHub | 60 req / hour | 5000 req / hour |

---

## 5. Usage | ä½¿ç”¨æ–¹æ³•

### 5.1 Basic Analysis | åŸºç¡€åˆ†æ

```bash
# Full analysis pipeline
python src/main.py --value-analysis

# Post-training dataset discovery
python src/main.py --focus sft           # SFT datasets
python src/main.py --focus preference    # RLHF/DPO datasets
python src/main.py --focus agent         # Agent datasets
python src/main.py --focus evaluation    # Benchmark datasets
```

### 5.2 Filtered Analysis | è¿‡æ»¤åˆ†æ

```bash
# High-value datasets only (score â‰¥ 60)
python src/main.py --value-analysis --min-score 60

# Top-tier institutions only
python src/main.py --value-analysis --top-institutions

# Positive growth trend only
python src/main.py --value-analysis --growth-only

# Domain-specific analysis
python src/main.py --focus robotics
python src/main.py --focus multimodal
```

### 5.3 Command Reference | å‘½ä»¤å‚è€ƒ

| Option | Description | Default |
|--------|-------------|---------|
| `--value-analysis` | Enable multi-signal scoring | Off |
| `--focus DOMAIN` | Filter by domain (sft, preference, agent, evaluation, robotics, rlhf, multimodal) | None |
| `--min-score N` | Minimum value score threshold | 0 |
| `--top-institutions` | Restrict to top-tier institutions | Off |
| `--growth-only` | Positive growth trend only | Off |
| `--opportunities` | Detect annotation opportunities | Off |
| `--quick` | Data collection only (skip analysis) | Off |

---

## 6. Output Specification | è¾“å‡ºè§„èŒƒ

### 6.1 Value Report | ä»·å€¼æŠ¥å‘Š

Generated at `data/value_report_YYYY-MM-DD.md`:

```markdown
# High-Value Dataset Report | é«˜ä»·å€¼æ•°æ®é›†æŠ¥å‘Š

## Executive Summary | æ‰§è¡Œæ‘˜è¦
- High-value (â‰¥60): 15 datasets
- Medium-value (40-59): 23 datasets
- Post-training datasets: 12 identified

## Top Datasets by Category | åˆ†ç±»æ’è¡Œ

### SFT Datasets
| Rank | Dataset | Score | Downloads | Institution |
|------|---------|-------|-----------|-------------|
| 1    | OpenOrca | 82    | 125,000   | OpenOrca    |

### Preference Datasets
| Rank | Dataset | Score | Downloads | Institution |
|------|---------|-------|-----------|-------------|
| 1    | UltraFeedback | 78 | 89,000 | OpenBMB |
```

### 6.2 JSON Export | JSON å¯¼å‡º

```json
{
  "datasets": [...],
  "analysis_timestamp": "2026-01-30T12:00:00Z",
  "post_training_summary": {
    "sft": {"count": 5, "items": [...]},
    "preference": {"count": 3, "items": [...]},
    "agent": {"count": 2, "items": [...]},
    "evaluation": {"count": 4, "items": [...]}
  }
}
```

---

## 7. Configuration | é…ç½®

### 7.1 Focus Areas | èšç„¦é¢†åŸŸ

```yaml
# config.yaml
focus_areas:
  sft:
    enabled: true
    keywords:
      - instruction tuning
      - supervised fine-tuning
      - ShareGPT
      - Alpaca
    hf_tags:
      - task_categories:conversational

  preference:
    enabled: true
    keywords:
      - DPO
      - RLHF
      - chosen rejected
      - human feedback
      - UltraFeedback

  agent:
    enabled: true
    keywords:
      - function calling
      - tool use
      - trajectory
      - SWE-bench
      - WebArena

  evaluation:
    enabled: true
    keywords:
      - benchmark
      - MMLU
      - HumanEval
      - GPQA
```

### 7.2 Organization Tracking | ç»„ç»‡è¿½è¸ª

```yaml
tracked_orgs:
  anthropic:
    - Anthropic
    - Claude
  lmsys:
    - LMSys
    - Chatbot Arena
    - Vicuna
  berkeley:
    - UC Berkeley
    - BAIR
    - Gorilla
    - Starling
```

---

## 8. Development | å¼€å‘

### 8.1 Project Structure | é¡¹ç›®ç»“æ„

```
ai-dataset-radar/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                    # Entry point
â”‚   â”œâ”€â”€ db.py                      # SQLite persistence layer
â”‚   â”œâ”€â”€ filters.py                 # Dataset filtering & classification
â”‚   â”œâ”€â”€ report.py                  # Report generation
â”‚   â”œâ”€â”€ notifiers.py               # Notification system
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ semantic_scholar.py    # Citation tracking
â”‚   â”‚   â”œâ”€â”€ huggingface.py         # HF datasets/models
â”‚   â”‚   â”œâ”€â”€ github.py              # Trending repositories
â”‚   â”‚   â”œâ”€â”€ arxiv.py               # Paper retrieval
â”‚   â”‚   â””â”€â”€ hf_papers.py           # HF daily papers
â”‚   â””â”€â”€ analyzers/
â”‚       â”œâ”€â”€ value_scorer.py        # Multi-factor scoring
â”‚       â”œâ”€â”€ model_card_analyzer.py # Model card parsing
â”‚       â”œâ”€â”€ trend.py               # Growth analysis
â”‚       â””â”€â”€ opportunities.py       # Business signal detection
â”œâ”€â”€ tests/                         # Test suite (50+ test cases)
â”œâ”€â”€ config.yaml                    # Configuration file
â””â”€â”€ requirements.txt               # Dependencies
```

### 8.2 Testing | æµ‹è¯•

```bash
# Run full test suite
python -m pytest tests/ -v

# Run with coverage report
python -m pytest tests/ --cov=src --cov-report=html

# Run specific test module
python -m pytest tests/test_business_intel.py -v
```

---

## 9. Roadmap | è·¯çº¿å›¾

**English:**

| Phase | Status | Description |
|-------|--------|-------------|
| Phase 1 | âœ… Complete | Core infrastructure (database, scrapers, trend analysis) |
| Phase 2 | âœ… Complete | Multi-source aggregation (GitHub, HF Papers, org tracking) |
| Phase 3 | âœ… Complete | Value scoring system (citations, SOTA, model cards) |
| Phase 3.5 | âœ… Complete | Post-training dataset classification (SFT, RLHF, Agent, Eval) |
| Phase 4 | ğŸ”„ Planned | Deep analysis (PDF extraction, LLM summarization) |
| Phase 5 | ğŸ”„ Planned | Automation (scheduled execution, alerting, monitoring) |

**ä¸­æ–‡:**

| é˜¶æ®µ | çŠ¶æ€ | æè¿° |
|------|------|------|
| é˜¶æ®µ 1 | âœ… å®Œæˆ | æ ¸å¿ƒåŸºç¡€è®¾æ–½ï¼ˆæ•°æ®åº“ã€çˆ¬è™«ã€è¶‹åŠ¿åˆ†æï¼‰ |
| é˜¶æ®µ 2 | âœ… å®Œæˆ | å¤šæºèšåˆï¼ˆGitHubã€HF è®ºæ–‡ã€æœºæ„è¿½è¸ªï¼‰ |
| é˜¶æ®µ 3 | âœ… å®Œæˆ | ä»·å€¼è¯„åˆ†ç³»ç»Ÿï¼ˆå¼•ç”¨ã€SOTAã€æ¨¡å‹å¡ï¼‰ |
| é˜¶æ®µ 3.5 | âœ… å®Œæˆ | åè®­ç»ƒæ•°æ®é›†åˆ†ç±»ï¼ˆSFTã€RLHFã€Agentã€Evalï¼‰ |
| é˜¶æ®µ 4 | ğŸ”„ è®¡åˆ’ä¸­ | æ·±åº¦åˆ†æï¼ˆPDF æå–ã€LLM æ‘˜è¦ï¼‰ |
| é˜¶æ®µ 5 | ğŸ”„ è®¡åˆ’ä¸­ | è‡ªåŠ¨åŒ–ï¼ˆå®šæ—¶æ‰§è¡Œã€å‘Šè­¦ã€ç›‘æ§ï¼‰ |

---

## 10. Citation | å¼•ç”¨

If you use this system in your research, please cite:

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨æœ¬ç³»ç»Ÿï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{ai_dataset_radar,
  author = {Liu, Xiaotong},
  title = {AI Dataset Radar: A Multi-Signal Intelligence System for High-Value AI Dataset Discovery},
  year = {2026},
  url = {https://github.com/liuxiaotong/ai-dataset-radar}
}
```

---

## License | è®¸å¯è¯

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## Acknowledgments | è‡´è°¢

This system builds upon APIs and data from:
- [Semantic Scholar](https://www.semanticscholar.org/) - Citation data
- [Hugging Face](https://huggingface.co/) - Dataset and model metadata
- [GitHub](https://github.com/) - Repository trending data
- [arXiv](https://arxiv.org/) - Preprint papers

æœ¬ç³»ç»ŸåŸºäºä»¥ä¸‹å¹³å°çš„ API å’Œæ•°æ®æ„å»ºï¼š
- [Semantic Scholar](https://www.semanticscholar.org/) - å¼•ç”¨æ•°æ®
- [Hugging Face](https://huggingface.co/) - æ•°æ®é›†å’Œæ¨¡å‹å…ƒæ•°æ®
- [GitHub](https://github.com/) - ä»“åº“è¶‹åŠ¿æ•°æ®
- [arXiv](https://arxiv.org/) - é¢„å°æœ¬è®ºæ–‡
